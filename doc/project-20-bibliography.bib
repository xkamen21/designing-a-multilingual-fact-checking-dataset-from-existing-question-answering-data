@inproceedings{mDPR,
 author = {Asai, Akari and Yu, Xinyan and Kasai, Jungo and Hajishirzi, Hanna},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {7547--7560},
 publisher = {Curran Associates, Inc.},
 title = {One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval},
 url = {https://proceedings.neurips.cc/paper/2021/file/3df07fdae1ab273a967aaa1d355b8bb6-Paper.pdf},
 volume = {34},
 year = {2021}
}

@inproceedings{DPR,
title = "Dense Passage Retrieval for Open-Domain Question Answering",
author = "Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau",
booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
month = nov,
year = "2020",
address = "Online",
publisher = "Association for Computational Linguistics",
url = "https://www.aclweb.org/anthology/2020.emnlp-main.550",
doi = "10.18653/v1/2020.emnlp-main.550",
pages = "6769--6781"
}

@article{gpt,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@misc{gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{rnn,
  author       = {Alex Sherstinsky},
  title        = {Fundamentals of Recurrent Neural Network {(RNN)} and Long Short-Term
                  Memory {(LSTM)} Network},
  journal      = {CoRR},
  volume       = {abs/1808.03314},
  year         = {2018},
  url          = {http://arxiv.org/abs/1808.03314},
  eprinttype    = {arXiv},
  eprint       = {1808.03314},
  timestamp    = {Sun, 02 Sep 2018 15:01:55 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1808-03314.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{transformers_vs_rnn,
  author       = {Surafel Melaku Lakew and
                  Mauro Cettolo and
                  Marcello Federico},
  title        = {A Comparison of Transformer and Recurrent Neural Networks on Multilingual
                  Neural Machine Translation},
  journal      = {CoRR},
  volume       = {abs/1806.06957},
  year         = {2018},
  url          = {http://arxiv.org/abs/1806.06957},
  eprinttype    = {arXiv},
  eprint       = {1806.06957},
  timestamp    = {Mon, 13 Aug 2018 16:45:58 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1806-06957.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{cloze,
  title={“Cloze Procedure”: A New Tool for Measuring Readability},
  author={Wilson L. Taylor},
  journal={Journalism \& Mass Communication Quarterly},
  year={1953},
  volume={30},
  pages={415 - 433}
}

@article{ner,
  author       = {Erik F. Tjong Kim Sang and
                  Fien De Meulder},
  title        = {Introduction to the CoNLL-2003 Shared Task: Language-Independent Named
                  Entity Recognition},
  journal      = {CoRR},
  volume       = {cs.CL/0306050},
  year         = {2003},
  url          = {http://arxiv.org/abs/cs/0306050},
  timestamp    = {Fri, 10 Jan 2020 12:58:18 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/cs-CL-0306050.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{mnli,
  author       = {Adina Williams and
                  Nikita Nangia and
                  Samuel R. Bowman},
  title        = {A Broad-Coverage Challenge Corpus for Sentence Understanding through
                  Inference},
  journal      = {CoRR},
  volume       = {abs/1704.05426},
  year         = {2017},
  url          = {http://arxiv.org/abs/1704.05426},
  eprinttype    = {arXiv},
  eprint       = {1704.05426},
  timestamp    = {Mon, 13 Aug 2018 16:47:54 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/WilliamsNB17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

% datasets
@article{tydiqa,
title = {TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages},
author = {Jonathan H. Clark and Eunsol Choi and Michael Collins and Dan Garrette and Tom Kwiatkowski and Vitaly Nikolaev and Jennimaria Palomaki},
year = {2020}
}

@inproceedings{xortydiqa,
    title   = {{XOR} {QA}: Cross-lingual Open-Retrieval Question Answering},
    author  = {Akari Asai and Jungo Kasai and Jonathan H. Clark and Kenton Lee and Eunsol Choi and Hannaneh Hajishirzi},
    booktitle={NAACL-HLT},
    year    = {2021}
}

@inproceedings{x-fact,
      title={{X-FACT: A New Benchmark Dataset for Multilingual Fact Checking}}, 
      author={Gupta, Ashim and Srikumar, Vivek},
      booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics",      
      month = jul,
      year = "2021",
      address = "Online",
      publisher = "Association for Computational Linguistics",
}

@inproceedings{fever,
    author = {Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Mittal, Arpit},
    title = {{FEVER}: a Large-scale Dataset for Fact Extraction and {VERification}},
    booktitle = {NAACL-HLT},
    year = {2018}
}

@article{faviq,
  author    = {Jungsoo Park and
               Sewon Min and
               Jaewoo Kang and
               Luke Zettlemoyer and
               Hannaneh Hajishirzi},
  title     = {FaVIQ: FAct Verification from Information-seeking Questions},
  journal   = {CoRR},
  volume    = {abs/2107.02153},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.02153},
  eprinttype = {arXiv},
  eprint    = {2107.02153},
  timestamp = {Wed, 07 Jul 2021 15:23:11 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-02153.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{politifact,
	title={Where Are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News},
	author={Vo, Nguyen and Lee, Kyumin},
	booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP 2020)},
	year={2020}
}

@inproceedings{liar,
    title = "{``}Liar, Liar Pants on Fire{''}: A New Benchmark Dataset for Fake News Detection",
    author = "Wang, William Yang",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    year = { 2017 }
}

@article{fakenewsnet,
  title={FakeNewsNet: A Data Repository with News Content, Social Context and Dynamic Information for Studying Fake News on Social Media},
  author={Shu, Kai and  Mahudeswaran, Deepak and Wang, Suhang and Lee, Dongwon and Liu, Huan},
  journal={arXiv preprint arXiv:1809.01286},
  year={2018}
}

@article{covert,
  title={Covert: A corpus of fact-checked biomedical covid-19 tweets},
  author={Mohr, Isabelle and W{\"u}hrl, Amelie and Klinger, Roman},
  journal={arXiv preprint arXiv:2204.12164},
  year={2022}
}

@article{NQ,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    journal = "Transactions of the Association for Computational Linguistics",
    year = "2019",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026",
}

@inproceedings{ambigqa,
    title = "{A}mbig{QA}: Answering Ambiguous Open-domain Questions",
    author = "Min, Sewon  and
      Michael, Julian  and
      Hajishirzi, Hannaneh  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2020",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.466",
}

@misc{IFCN,
  title = {International Fact Checking Network},
  howpublished = {\url{https://ifcncodeofprinciples.poynter.org}},
  note = {Accessed: 2023-05-06}
}
@misc{IFCN2,
 author = {Orsek, Baybars},
 title = {International Fact Checking Network},
 url = {https://ifcncodeofprinciples.poynter.org},
 lastchecked = {2023-05-06},
 originalyear = {2015}
}

@article{msmarco,
  author       = {Tri Nguyen and
                  Mir Rosenberg and
                  Xia Song and
                  Jianfeng Gao and
                  Saurabh Tiwary and
                  Rangan Majumder and
                  Li Deng},
  title        = {{MS} {MARCO:} {A} Human Generated MAchine Reading COmprehension Dataset},
  journal      = {CoRR},
  volume       = {abs/1611.09268},
  year         = {2016},
  url          = {http://arxiv.org/abs/1611.09268},
  eprinttype    = {arXiv},
  eprint       = {1611.09268},
  timestamp    = {Mon, 13 Aug 2018 16:49:03 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/NguyenRSGTMD16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


% information retrievals

@article{vectore_space, 
    author = {Salton, G. and Wong, A. and Yang, C. S.}, 
    title = {A Vector Space Model for Automatic Indexing}, 
    year = {1975}, 
    publisher = {Association for Computing Machinery}, 
}

@article{LSI,
	title = {A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge},
	year = {1997},
	journal = {Psychological Review},
	doi = {10.1037/0033-295x.104.2.211},
	pages = {211--240},
	volume = {104},
	number = {2},
	author = {Thomas K. Landauer and Susan T. Dumais}
}

@misc{nn_models,
      title={Neural network models}, 
      author={Plamen Dimitrov},
      year={2023},
      eprint={2301.02987},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@incollection{cosine_similarity,
    title = {2 - Getting to Know Your Data},
    editor = {Jiawei Han and Micheline Kamber and Jian Pei},
    booktitle = {Data Mining (Third Edition)},
    publisher = {Morgan Kaufmann},
    edition = {Third Edition},
    address = {Boston},
    pages = {39-82},
    year = {2012},
    series = {The Morgan Kaufmann Series in Data Management Systems},
    isbn = {978-0-12-381479-1},
    doi = {https://doi.org/10.1016/B978-0-12-381479-1.00002-2},
    url = {https://www.sciencedirect.com/science/article/pii/B9780123814791000022},
    author = {Jiawei Han and Micheline Kamber and Jian Pei}
}

@article{cnn,
  author       = {Keiron O'Shea and
                  Ryan Nash},
  title        = {An Introduction to Convolutional Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1511.08458},
  year         = {2015},
  url          = {http://arxiv.org/abs/1511.08458},
  eprinttype    = {arXiv},
  eprint       = {1511.08458},
  timestamp    = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/OSheaN15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{bert,
  author       = {Jacob Devlin and
                  Ming{-}Wei Chang and
                  Kenton Lee and
                  Kristina Toutanova},
  title        = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                  Understanding},
  journal      = {CoRR},
  volume       = {abs/1810.04805},
  year         = {2018},
  url          = {http://arxiv.org/abs/1810.04805},
  eprinttype    = {arXiv},
  eprint       = {1810.04805},
  timestamp    = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{mbert,
  author       = {Telmo Pires and
                  Eva Schlinger and
                  Dan Garrette},
  title        = {How multilingual is Multilingual BERT?},
  journal      = {CoRR},
  volume       = {abs/1906.01502},
  year         = {2019},
  url          = {http://arxiv.org/abs/1906.01502},
  eprinttype    = {arXiv},
  eprint       = {1906.01502},
  timestamp    = {Thu, 13 Jun 2019 13:36:00 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1906-01502.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{BM25,
url = {http://dx.doi.org/10.1561/1500000019},
year = {2009},
volume = {3},
journal = {Foundations and Trends® in Information Retrieval},
title = {The Probabilistic Relevance Framework: BM25 and Beyond},
doi = {10.1561/1500000019},
issn = {1554-0669},
number = {4},
pages = {333-389},
author = {Stephen Robertson and Hugo Zaragoza}
}

@inproceedings{BM25_variants,
author = {Trotman, Andrew and Puurula, Antti and Burgess, Blake},
title = {Improvements to BM25 and Language Models Examined},
year = {2014},
isbn = {9781450330008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2682862.2682863},
doi = {10.1145/2682862.2682863},
abstract = {Recent work on search engine ranking functions report improvements on BM25 and Language Models with Dirichlet Smoothing. In this investigation 9 recent ranking functions (BM25, BM25+, BM25T, BM25-adpt, BM25L, TF1°δ°p\texttimes{}ID, LM-DS, LM-PYP, and LM-PYP-TFIDF) are compared by training on the INEX 2009 Wikipedia collection and testing on INEX 2010 and 9 TREC collections. We find that once trained (using particle swarm optimization) there is very little difference in performance between these functions, that relevance feedback is effective, that stemming is effective, and that it remains unclear which function is best over-all.},
booktitle = {Proceedings of the 2014 Australasian Document Computing Symposium},
pages = {58–65},
numpages = {8},
keywords = {Procrastination, Document Retrieval, Relevance Ranking},
location = {Melbourne, VIC, Australia},
series = {ADCS '14}
}

@misc{mDPR_training,
      title={Towards Best Practices for Training Multilingual Dense Retrieval Models}, 
      author={Xinyu Zhang and Kelechi Ogueji and Xueguang Ma and Jimmy Lin},
      year={2022},
      eprint={2204.02363},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

% translator
@InProceedings{helsinki,
  author = {J{\"o}rg Tiedemann and Santhosh Thottingal},
  title = {{OPUS-MT} — {B}uilding open translation services for the {W}orld},
  booktitle = {Proceedings of the 22nd Annual Conferenec of the European Association for Machine Translation (EAMT)},
  year = {2020},
  address = {Lisbon, Portugal}
 }

@inproceedings{marian,
    title = "{M}arian: Fast Neural Machine Translation in {C}++",
    author = "Junczys-Dowmunt, Marcin  and
      Grundkiewicz, Roman  and
      Dwojak, Tomasz  and
      Hoang, Hieu  and
      Heafield, Kenneth  and
      Neckermann, Tom  and
      Seide, Frank  and
      Germann, Ulrich  and
      Aji, Alham Fikri  and
      Bogoychev, Nikolay  and
      Martins, Andr{\'e} F. T.  and
      Birch, Alexandra",
    booktitle = "Proceedings of {ACL} 2018, System Demonstrations",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-4020",
    doi = "10.18653/v1/P18-4020",
    pages = "116--121",
    abstract = "We present Marian, an efficient and self-contained Neural Machine Translation framework with an integrated automatic differentiation engine based on dynamic computation graphs. Marian is written entirely in C++. We describe the design of the encoder-decoder framework and demonstrate that a research-friendly toolkit can achieve high training and translation speed.",
}

@misc{opus-mt,
  doi = {10.48550/ARXIV.2212.01936},
  url = {https://arxiv.org/abs/2212.01936},
  author = {Tiedemann, Jörg and Aulamo, Mikko and Bakshandaeva, Daria and Boggia, Michele and Grönroos, Stig-Arne and Nieminen, Tommi and Raganato, Alessandro and Scherrer, Yves and Vazquez, Raul and Virpioja, Sami},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Democratizing Machine Translation with OPUS-MT},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}



@misc{LSTM,
  doi = {10.48550/ARXIV.2105.06756},
  url = {https://arxiv.org/abs/2105.06756},
  author = {Vennerød, Christian Bakke and Kjærran, Adrian and Bugge, Erling Stray},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Long Short-term Memory RNN},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{GRU,
  doi = {10.48550/ARXIV.1412.3555},
  url = {https://arxiv.org/abs/1412.3555},
  author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  keywords = {Neural and Evolutionary Computing (cs.NE), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{transformer,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{T5,
  doi = {10.48550/ARXIV.1910.10683},
  url = {https://arxiv.org/abs/1910.10683},
  author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{mt5,
  author       = {Linting Xue and
                  Noah Constant and
                  Adam Roberts and
                  Mihir Kale and
                  Rami Al{-}Rfou and
                  Aditya Siddhant and
                  Aditya Barua and
                  Colin Raffel},
  title        = {mT5: {A} massively multilingual pre-trained text-to-text transformer},
  journal      = {CoRR},
  volume       = {abs/2010.11934},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.11934},
  eprinttype    = {arXiv},
  eprint       = {2010.11934},
  timestamp    = {Tue, 27 Oct 2020 11:22:08 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-11934.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

% others
@article{mdpr_ref1,
  author       = {Jordi Armengol{-}Estap{\'{e}} and
                  Casimiro Pio Carrino and
                  Carlos Rodr{\'{\i}}guez Penagos and
                  Ona De Gibert Bonet and
                  Carme Armentano{-}Oller and
                  Aitor Gonzalez{-}Agirre and
                  Maite Melero and
                  Marta Villegas},
  title        = {Are Multilingual Models the Best Choice for Moderately Under-resourced
                  Languages? {A} Comprehensive Assessment for Catalan},
  journal      = {CoRR},
  volume       = {abs/2107.07903},
  year         = {2021},
  url          = {https://arxiv.org/abs/2107.07903},
  eprinttype    = {arXiv},
  eprint       = {2107.07903},
  timestamp    = {Wed, 21 Jul 2021 15:55:35 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2107-07903.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{mdpr_ref2,
  author       = {Louis Martin and
                  Benjamin M{\"{u}}ller and
                  Pedro Javier Ortiz Su{\'{a}}rez and
                  Yoann Dupont and
                  Laurent Romary and
                  {\'{E}}ric Villemonte de la Clergerie and
                  Djam{\'{e}} Seddah and
                  Beno{\^{\i}}t Sagot},
  title        = {CamemBERT: a Tasty French Language Model},
  journal      = {CoRR},
  volume       = {abs/1911.03894},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.03894},
  eprinttype    = {arXiv},
  eprint       = {1911.03894},
  timestamp    = {Sun, 01 Dec 2019 20:31:34 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-03894.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{mdpr_ref3,
  author       = {Samuel R{\"{o}}nnqvist and
                  Jenna Kanerva and
                  Tapio Salakoski and
                  Filip Ginter},
  title        = {Is Multilingual {BERT} Fluent in Language Generation?},
  journal      = {CoRR},
  volume       = {abs/1910.03806},
  year         = {2019},
  url          = {http://arxiv.org/abs/1910.03806},
  eprinttype    = {arXiv},
  eprint       = {1910.03806},
  timestamp    = {Wed, 16 Oct 2019 16:25:53 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1910-03806.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{mdpr_ref4,
  author       = {Antti Virtanen and
                  Jenna Kanerva and
                  Rami Ilo and
                  Jouni Luoma and
                  Juhani Luotolahti and
                  Tapio Salakoski and
                  Filip Ginter and
                  Sampo Pyysalo},
  title        = {Multilingual is not enough: {BERT} for Finnish},
  journal      = {CoRR},
  volume       = {abs/1912.07076},
  year         = {2019},
  url          = {http://arxiv.org/abs/1912.07076},
  eprinttype    = {arXiv},
  eprint       = {1912.07076},
  timestamp    = {Fri, 03 Jan 2020 16:10:45 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1912-07076.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{pytorch,
  author       = {Adam Paszke and
                  Sam Gross and
                  Francisco Massa and
                  Adam Lerer and
                  James Bradbury and
                  Gregory Chanan and
                  Trevor Killeen and
                  Zeming Lin and
                  Natalia Gimelshein and
                  Luca Antiga and
                  Alban Desmaison and
                  Andreas K{\"{o}}pf and
                  Edward Z. Yang and
                  Zach DeVito and
                  Martin Raison and
                  Alykhan Tejani and
                  Sasank Chilamkurthy and
                  Benoit Steiner and
                  Lu Fang and
                  Junjie Bai and
                  Soumith Chintala},
  title        = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  journal      = {CoRR},
  volume       = {abs/1912.01703},
  year         = {2019},
  url          = {http://arxiv.org/abs/1912.01703},
  eprinttype    = {arXiv},
  eprint       = {1912.01703},
  timestamp    = {Tue, 02 Nov 2021 15:18:32 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1912-01703.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{wikiextractor,
  author = {Giusepppe Attardi},
  title = {WikiExtractor},
  year = {2015},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/attardi/wikiextractor}}
}

@article{back-propagation,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group UK London}
}

@article{elman,
  title={Finding structure in time},
  author={Elman, Jeffrey L},
  journal={Cognitive science},
  volume={14},
  number={2},
  pages={179--211},
  year={1990},
  publisher={Wiley Online Library}
}

@article{roberta,
  author       = {Yinhan Liu and
                  Myle Ott and
                  Naman Goyal and
                  Jingfei Du and
                  Mandar Joshi and
                  Danqi Chen and
                  Omer Levy and
                  Mike Lewis and
                  Luke Zettlemoyer and
                  Veselin Stoyanov},
  title        = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal      = {CoRR},
  volume       = {abs/1907.11692},
  year         = {2019},
  url          = {http://arxiv.org/abs/1907.11692},
  eprinttype    = {arXiv},
  eprint       = {1907.11692},
  timestamp    = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{relu,
  author       = {Abien Fred Agarap},
  title        = {Deep Learning using Rectified Linear Units (ReLU)},
  journal      = {CoRR},
  volume       = {abs/1803.08375},
  year         = {2018},
  url          = {http://arxiv.org/abs/1803.08375},
  eprinttype    = {arXiv},
  eprint       = {1803.08375},
  timestamp    = {Mon, 13 Aug 2018 16:47:13 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1803-08375.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{feed-forward,
  author={Bebis, G. and Georgiopoulos, M.},
  journal={IEEE Potentials}, 
  title={Feed-forward neural networks}, 
  year={1994},
  volume={13},
  number={4},
  pages={27-31},
  doi={10.1109/45.329294}
}

@article{regularization,
  author       = {Samuel R. Bowman and
                  Luke Vilnis and
                  Oriol Vinyals and
                  Andrew M. Dai and
                  Rafal J{\'{o}}zefowicz and
                  Samy Bengio},
  title        = {Generating Sentences from a Continuous Space},
  journal      = {CoRR},
  volume       = {abs/1511.06349},
  year         = {2015},
  url          = {http://arxiv.org/abs/1511.06349},
  eprinttype    = {arXiv},
  eprint       = {1511.06349},
  timestamp    = {Mon, 13 Aug 2018 16:47:06 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/BowmanVVDJB15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{teacher_forcing,
  author={Williams, Ronald J. and Zipser, David},
  journal={Neural Computation}, 
  title={A Learning Algorithm for Continually Running Fully Recurrent Neural Networks}, 
  year={1989},
  volume={1},
  number={2},
  pages={270-280},
  doi={10.1162/neco.1989.1.2.270}
}

@inproceedings{wmt,
  title={Findings of the 2014 workshop on statistical machine translation},
  author={Bojar, Ond{\v{r}}ej and Buck, Christian and Federmann, Christian and Haddow, Barry and Koehn, Philipp and Leveling, Johannes and Monz, Christof and Pecina, Pavel and Post, Matt and Saint-Amand, Herve and others},
  booktitle={Proceedings of the ninth workshop on statistical machine translation},
  pages={12--58},
  year={2014}
}

@article{squad,
  author       = {Pranav Rajpurkar and
                  Jian Zhang and
                  Konstantin Lopyrev and
                  Percy Liang},
  title        = {SQuAD: 100, 000+ Questions for Machine Comprehension of Text},
  journal      = {CoRR},
  volume       = {abs/1606.05250},
  year         = {2016},
  url          = {http://arxiv.org/abs/1606.05250},
  eprinttype    = {arXiv},
  eprint       = {1606.05250},
  timestamp    = {Mon, 24 Aug 2020 14:01:25 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RajpurkarZLL16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{daily_mail,
  author       = {Karl Moritz Hermann and
                  Tom{\'{a}}s Kocisk{\'{y}} and
                  Edward Grefenstette and
                  Lasse Espeholt and
                  Will Kay and
                  Mustafa Suleyman and
                  Phil Blunsom},
  title        = {Teaching Machines to Read and Comprehend},
  journal      = {CoRR},
  volume       = {abs/1506.03340},
  year         = {2015},
  url          = {http://arxiv.org/abs/1506.03340},
  eprinttype    = {arXiv},
  eprint       = {1506.03340},
  timestamp    = {Mon, 13 Aug 2018 16:49:00 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/HermannKGEKSB15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{superglue,
  author       = {Alex Wang and
                  Yada Pruksachatkun and
                  Nikita Nangia and
                  Amanpreet Singh and
                  Julian Michael and
                  Felix Hill and
                  Omer Levy and
                  Samuel R. Bowman},
  title        = {SuperGLUE: {A} Stickier Benchmark for General-Purpose Language Understanding
                  Systems},
  journal      = {CoRR},
  volume       = {abs/1905.00537},
  year         = {2019},
  url          = {http://arxiv.org/abs/1905.00537},
  eprinttype    = {arXiv},
  eprint       = {1905.00537},
  timestamp    = {Mon, 27 May 2019 13:15:00 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1905-00537.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{glue,
  author       = {Alex Wang and
                  Amanpreet Singh and
                  Julian Michael and
                  Felix Hill and
                  Omer Levy and
                  Samuel R. Bowman},
  title        = {{GLUE:} {A} Multi-Task Benchmark and Analysis Platform for Natural
                  Language Understanding},
  journal      = {CoRR},
  volume       = {abs/1804.07461},
  year         = {2018},
  url          = {http://arxiv.org/abs/1804.07461},
  eprinttype    = {arXiv},
  eprint       = {1804.07461},
  timestamp    = {Mon, 13 Aug 2018 16:46:56 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1804-07461.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{glu,
  author       = {Noam Shazeer},
  title        = {{GLU} Variants Improve Transformer},
  journal      = {CoRR},
  volume       = {abs/2002.05202},
  year         = {2020},
  url          = {https://arxiv.org/abs/2002.05202},
  eprinttype    = {arXiv},
  eprint       = {2002.05202},
  timestamp    = {Fri, 14 Feb 2020 12:07:41 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2002-05202.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{mt5_approach,
    title = "Unsupervised Cross-lingual Representation Learning at Scale",
    author = "Conneau, Alexis  and
      Khandelwal, Kartikay  and
      Goyal, Naman  and
      Chaudhary, Vishrav  and
      Wenzek, Guillaume  and
      Guzm{\'a}n, Francisco  and
      Grave, Edouard  and
      Ott, Myle  and
      Zettlemoyer, Luke  and
      Stoyanov, Veselin",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.747",
    doi = "10.18653/v1/2020.acl-main.747",
    pages = "8440--8451",
    abstract = "This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6{\%} average accuracy on XNLI, +13{\%} average F1 score on MLQA, and +2.4{\%} F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7{\%} in XNLI accuracy for Swahili and 11.4{\%} for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code and models publicly available.",
}

@article{mt5_approach2,
  author       = {Naveen Arivazhagan and
                  Ankur Bapna and
                  Orhan Firat and
                  Dmitry Lepikhin and
                  Melvin Johnson and
                  Maxim Krikun and
                  Mia Xu Chen and
                  Yuan Cao and
                  George F. Foster and
                  Colin Cherry and
                  Wolfgang Macherey and
                  Zhifeng Chen and
                  Yonghui Wu},
  title        = {Massively Multilingual Neural Machine Translation in the Wild: Findings
                  and Challenges},
  journal      = {CoRR},
  volume       = {abs/1907.05019},
  year         = {2019},
  url          = {http://arxiv.org/abs/1907.05019},
  eprinttype    = {arXiv},
  eprint       = {1907.05019},
  timestamp    = {Thu, 14 Jan 2021 12:12:19 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1907-05019.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

@inproceedings{f-score,
    title = "Complementarity, {F}-score, and {NLP} Evaluation",
    author = "Derczynski, Leon",
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    month = may,
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L16-1040",
    pages = "261--266",
    abstract = "This paper addresses the problem of quantifying the differences between entity extraction systems, where in general only a small proportion a document should be selected. Comparing overall accuracy is not very useful in these cases, as small differences in accuracy may correspond to huge differences in selections over the target minority class. Conventionally, one may use per-token complementarity to describe these differences, but it is not very useful when the set is heavily skewed. In such situations, which are common in information retrieval and entity recognition, metrics like precision and recall are typically used to describe performance. However, precision and recall fail to describe the differences between sets of objects selected by different decision strategies, instead just describing the proportional amount of correct and incorrect objects selected. This paper presents a method for measuring complementarity for precision, recall and F-score, quantifying the difference between entity extraction approaches.",
}

@book{rouge_book, author = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford}, title = {Introduction to Algorithms, Third Edition}, year = {2009}, isbn = {0262033844}, publisher = {The MIT Press}, edition = {3rd}, abstract = {If you had to buy just one text on algorithms, Introduction to Algorithms is a magnificent choice. The book begins by considering the mathematical foundations of the analysis of algorithms and maintains this mathematical rigor throughout the work. The tools developed in these opening sections are then applied to sorting, data structures, graphs, and a variety of selected algorithms including computational geometry, string algorithms, parallel models of computation, fast Fourier transforms (FFTs), and more. This book's strength lies in its encyclopedic range, clear exposition, and powerful analysis. Pseudo-code explanation of the algorithms coupled with proof of their accuracy makes this book is a great resource on the basic tools used to analyze the performance of algorithms.} }

@article{misinformation,
author = {Stephan Lewandowsky and Ullrich K. H. Ecker and Colleen M. Seifert and Norbert Schwarz and John Cook},
title ={Misinformation and Its Correction: Continued Influence and Successful Debiasing},
journal = {Psychological Science in the Public Interest},
volume = {13},
number = {3},
pages = {106-131},
year = {2012},
doi = {10.1177/1529100612451018},
    note ={PMID: 26173286},

URL = { 
        https://doi.org/10.1177/1529100612451018
    
},
eprint = { 
        https://doi.org/10.1177/1529100612451018
    
}
,
    abstract = { The widespread prevalence and persistence of misinformation in contemporary societies, such as the false belief that there is a link between childhood vaccinations and autism, is a matter of public concern. For example, the myths surrounding vaccinations, which prompted some parents to withhold immunization from their children, have led to a marked increase in vaccine-preventable disease, as well as unnecessary public expenditure on research and public-information campaigns aimed at rectifying the situation.We first examine the mechanisms by which such misinformation is disseminated in society, both inadvertently and purposely. Misinformation can originate from rumors but also from works of fiction, governments and politicians, and vested interests. Moreover, changes in the media landscape, including the arrival of the Internet, have fundamentally influenced the ways in which information is communicated and misinformation is spread.We next move to misinformation at the level of the individual, and review the cognitive factors that often render misinformation resistant to correction. We consider how people assess the truth of statements and what makes people believe certain things but not others. We look at people’s memory for misinformation and answer the questions of why retractions of misinformation are so ineffective in memory updating and why efforts to retract misinformation can even backfire and, ironically, increase misbelief. Though ideology and personal worldviews can be major obstacles for debiasing, there nonetheless are a number of effective techniques for reducing the impact of misinformation, and we pay special attention to these factors that aid in debiasing.We conclude by providing specific recommendations for the debunking of misinformation. These recommendations pertain to the ways in which corrections should be designed, structured, and applied in order to maximize their impact. Grounded in cognitive psychological theory, these recommendations may help practitioners—including journalists, health professionals, educators, and science communicators—design effective misinformation retractions, educational tools, and public-information campaigns. }
}

@article{mrtydi,
  author       = {Xinyu Zhang and
                  Xueguang Ma and
                  Peng Shi and
                  Jimmy Lin},
  title        = {Mr. TyDi: {A} Multi-lingual Benchmark for Dense Retrieval},
  journal      = {CoRR},
  volume       = {abs/2108.08787},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.08787},
  eprinttype    = {arXiv},
  eprint       = {2108.08787},
  timestamp    = {Fri, 18 Mar 2022 08:02:54 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2108-08787.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{beamsearch,
  author       = {Markus Freitag and
                  Yaser Al{-}Onaizan},
  title        = {Beam Search Strategies for Neural Machine Translation},
  journal      = {CoRR},
  volume       = {abs/1702.01806},
  year         = {2017},
  url          = {http://arxiv.org/abs/1702.01806},
  eprinttype    = {arXiv},
  eprint       = {1702.01806},
  timestamp    = {Mon, 13 Aug 2018 16:49:02 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/FreitagA17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{lewandovski,
 ISSN = {15291006},
 URL = {http://www.jstor.org/stable/23484653},
 abstract = {The widespread prevalence and persistence of misinformation in contemporary societies, such as the false belief that there is a link between childhood vaccinations and autism, is a matter of public concern. For example, the myths surrounding vaccinations, which prompted some parents to withhold immunization from their children, have led to a marked increase in vaccine-preventable disease, as well as unnecessary public expenditure on research and public-information campaigns aimed at rectifying the situation. We first examine the mechanisms by which such misinformation is disseminated in society, both inadvertently and purposely. Misinformation can originate from rumors but also from works of fiction, governments and politicians, and vested interests. Moreover, changes in the media landscape, including the arrival of the Internet, have fundamentally influenced the ways in which information is communicated and misinformation is spread. We next move to misinformation at the level of the individual, and review the cognitive factors that often render misinformation resistant to correction. We consider how people assess the truth of statements and what makes people believe certain things but not others. We look at people's memory for misinformation and answer the questions of why retractions of misinformation are so ineffective in memory updating and why efforts to retract misinformation can even backfire and, ironically, increase misbelief. Though ideology and personal worldviews can be major obstacles for debiasing, there nonetheless are a number of effective techniques for reducing the impact of misinformation, and we pay special attention to these factors that aid in debiasing. We conclude by providing specific recommendations for the debunking of misinformation. These recommendations pertain to the ways in which corrections should be designed, structured, and applied in order to maximize their impact. Grounded in cognitive psychological theory, these recommendations may help practitioners—including journalists, health professionals, educators, and science communicators—design effective misinformation retractions, educational tools, and public-information campaigns.},
 author = {Stephan Lewandowsky and Ullrich K. H. Ecker and Colleen M. Seifert and Norbert Schwarz and John Cook},
 journal = {Psychological Science in the Public Interest},
 number = {3},
 pages = {106--131},
 publisher = {Sage Publications, Inc.},
 title = {Misinformation and Its Correction: Continued Influence and Successful Debiasing},
 urldate = {2023-05-16},
 volume = {13},
 year = {2012}
}